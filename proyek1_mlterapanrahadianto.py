# -*- coding: utf-8 -*-
"""Proyek1_MLterapanRahadianto.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f2K_YliRKlJJkE5MEmWa0yk_JcedhgwS

1. import library yang dibutuhkan
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM
from google.colab import files
filenya = files.upload()

"""2. memasukkan dataset yang akan digunakan"""

housePrice = pd.read_csv('kc_house_data.csv')
housePrice

"""3. terdapat 8 kolom yaitu Area	Room	Parking	Warehouse	Elevator	Price, price(usd), dan address. namun kita hapus 2 kolom  yaitu  price(usd), dan address. **selanjutnya mengecek informasi tipedata pada dataset**"""

housePrice.info()

"""4.  mengecek deskripsi statistik data dengan fitur describe()."""

housePrice.describe()

"""5. mengecek ada berapa missing value yang ada pada kolom room"""

x = (housePrice.bedrooms == 0).sum()
 
print("Nilai 0 di kolom  Room ada: ", x)

"""6. menghapus data baris yang terdapat nilai 0 pada kolom room"""

# Drop baris dengan nilai 'bedrooms' = 0
housePrice = housePrice.loc[(housePrice[['bedrooms']]!=0).all(axis=1)]
 
# Cek ukuran data untuk memastikan baris sudah di-drop
housePrice.shape

"""7. melakukan visualisasi pada fitur numerik sisanya.
**Area**
"""

sns.boxplot(x=housePrice['view'])

"""8. melakukan visualisasi pada fitur numerik sisanya.
**Room**
"""

sns.boxplot(x=housePrice['bedrooms'])

"""9. membagi fitur menjadi dua bagian dengan proses Univariate Analysis"""

# numerical features dan categorical features.

numerical_features = [ 'floors', 'price', 'bedroom']
categorical_features = ['date']

"""10. -	Melakukan Exploratory Data Analysis, untuk menunjukkan hubungan antara dua atau lebih variabel pada data. Pada kasus kali ini kita melakukan nya pada fitur katagori yaitu parking, warehouse, elevator, dan pada fitur numerik yaitu harga"""

#Categorical Features
#Fitur tanggal
feature = categorical_features[0]
count = housePrice[feature].value_counts()
percent = 100*housePrice[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

#Numerical Features
#Selanjutnya, untuk fitur numerik, kita akan melihat histogram masing-masing fiturnya menggunakan code berikut.

housePrice.hist(bins=50, figsize=(20,15))
plt.show()

"""11. mengecek rata-rata harga terhadap masing-masing fitur untuk mengetahui pengaruh fitur kategori terhadap harga."""

#Categorical Features

cat_features = housePrice.select_dtypes(include='bool').columns.to_list()
 
for col in cat_features:
  sns.catplot(x=col, y="Price", kind="bar", dodge=False, height = 4, aspect = 3,  data=housePrice, palette="Set3")
  plt.title("Rata-rata 'Price' Relatif terhadap - {}".format(col))

#Untuk mengevaluasi skor korelasinya, gunakan fungsi corr().

plt.figure(figsize=(10, 8))
correlation_matrix = housePrice.corr().round(2)
 
# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""12. 	Kita memiiki tiga variable kategori yaitu parking, warehouse, dan elevator. Untuk melakukan proses encoding fitur kategori agar menjadi variable numerik, salah satu teknik yang umum dilakukan adalah teknik one-hot-encoding"""

#Data Preparation

from sklearn.preprocessing import  OneHotEncoder
housePrice = pd.concat([housePrice, pd.get_dummies(housePrice['date'], prefix='date')],axis=1)
housePrice.drop(['date'], axis=1, inplace=True)
housePrice.head(20)

"""13. 	Selanjutnya membagi dataset menjadi data train dan data test agar dapat mempertahankan data yang ada menguji seberapa baik generalisasi model terhadap data baru"""

#Train-Test-Split

from sklearn.model_selection import train_test_split
 
X = housePrice.drop(["price"],axis =1)
y = housePrice["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

#Untuk mengecek jumlah sampel pada masing-masing bagian, kita gunakan code berikut.

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""14.Untuk menghindari kebocoran informasi pada data uji, kita hanya akan menerapkan fitur standarisasi pada data latih."""

#standarisasi

from sklearn.preprocessing import StandardScaler
 
numerical_features = ['floors', 'bedrooms']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

#Untuk mengecek nilai mean dan standar deviasi pada setelah proses standarisasi

X_train[numerical_features].describe().round(4)

"""15. Pada tahap modelling menggunaka  tiga model yaitu: K-Nearest Neighbor (KNN), Random Forest (RF), dan  Boosting Algorithm"""

#Model Development dengan K-Nearest Neighbor

# Siapkan dataframe untuk analisis model
models = pd.DataFrame(index=['train_mse', 'test_mse'], 
                      columns=['KNN', 'RandomForest', 'Boosting'])

#melatih data dengan KNN, tuliskan code berikut.

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
 
knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)
 
models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

#Model Development dengan Random Forest

# Impor library yang dibutuhkan
from sklearn.ensemble import RandomForestRegressor
 
# buat model prediksi
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
 
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

#Model Development dengan Boosting Algorithm

from sklearn.ensemble import AdaBoostRegressor
 
boosting = AdaBoostRegressor(learning_rate=0.05, random_state=55)                             
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""16. Evaluasi Model.
scaling terhadap fitur numerik pada X_test sehingga memiliki rata-rata=0 dan varians=1
"""

#proses scaling, implementasikan kode berikut:
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""17. evaluasi model. 
 Buat variabel mse yang isinya adalah dataframe nilai mse data train dan test pada masing-masing algoritma
"""

#evaluasi ketiga model kita dengan metrik MSE yang telah dijelaskan di atas
mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])
 
# Buat dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}
 
# Hitung Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
 
# Panggil mse
mse

#Untuk memudahkan, mari kita plot metrik tersebut dengan bar chart. Implementasikan kode di bawah ini:


fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=1)
ax.grid(zorder=0)

"""18. mengujinya, mari kita buat prediksi menggunakan beberapa harga dari data test"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)

"""***Model algoritma Boosting memberikan nilai eror yang paling kecil. Sedangkan model dengan RF memiliki eror yang paling besar***"""